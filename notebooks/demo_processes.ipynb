{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo all Thunderbird WPS Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how the scripts from PCIC's [climate-explorer-data-prep](https://github.com/pacificclimate/climate-explorer-data-prep/blob/master/README.md) repository are used as Web Processing Service (WPS) processes in thunderbird. Before a process can be run, an instance of `thunderbird` must be activated by executing `thunderbird start` on a terminal. Each process takes netcdf files as input and, unless otherwise stated, outputs a metalink between the resulting netcdf files to allow them to be downloaded. Netcdf files from local storage or an opendap server can be used as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdy import WPSClient\n",
    "import requests\n",
    "from pkg_resources import resource_filename\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if os.path.basename(os.getcwd()) != \"thunderbird\": # Ensure current directory is always 'thunderbird' for 'resource_filename' to work\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up wps application\n",
    "url = 'http://localhost:5001/wps'\n",
    "thunderbird = WPSClient(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m            WPSClient\n",
       "\u001b[0;31mString form:\u001b[0m     <birdy.client.base.WPSClient object at 0x7f7288307978>\n",
       "\u001b[0;31mFile:\u001b[0m            ~/github/pcic/thunderbird/notebooks/demo_venv/lib/python3.6/site-packages/birdy/client/base.py\n",
       "\u001b[0;31mDocstring:\u001b[0m      \n",
       "A Web Processing Service for Climate Explorer data preparation\n",
       "\n",
       "Processes\n",
       "---------\n",
       "\n",
       "generate_climos\n",
       "    Generate files containing climatological means from input files of daily, monthly, or yearly data that adhere to the PCIC metadata standard (and consequently to CMIP5 and CF standards).\n",
       "\n",
       "generate_prsn\n",
       "    Generate precipitation as snow file from precipitation and minimum/maximum temperature data\n",
       "\n",
       "update_metadata\n",
       "    Update file containing missing, invalid, or incorrectly named global or variable metadata attributes\n",
       "\n",
       "split_merged_climos\n",
       "    Split climo means files into one file per time interval\n",
       "\n",
       "hello\n",
       "    Just says a friendly Hello.Returns a literal string output with Hello plus the inputed name.\n",
       "\n",
       "decompose_flow_vectors\n",
       "    Process an indexed flow direction netCDF into a vectored netCDF suitable for ncWMS display\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "Returns a class where every public method is a WPS process available at\n",
       "the given url.\n",
       "\n",
       "Example:\n",
       "    >>> emu = WPSClient(url='<server url>')\n",
       "    >>> emu.hello('stranger')\n",
       "    'Hello stranger'\n",
       "\u001b[0;31mInit docstring:\u001b[0m \n",
       "Args:\n",
       "    url (str): Link to WPS provider. config (Config): an instance\n",
       "    processes: Specify a subset of processes to bind. Defaults to all\n",
       "        processes.\n",
       "    converters (dict): Correspondence of {mimetype: class} to convert\n",
       "        this mimetype to a python object.\n",
       "    username (str): passed to :class:`owslib.wps.WebProcessingService`\n",
       "    password (str): passed to :class:`owslib.wps.WebProcessingService`\n",
       "    headers (str): passed to :class:`owslib.wps.WebProcessingService`\n",
       "    auth (requests.auth.AuthBase): requests-style auth class to authenticate,\n",
       "        see https://2.python-requests.org/en/master/user/authentication/\n",
       "    verify (bool): passed to :class:`owslib.wps.WebProcessingService`\n",
       "    cert (str): passed to :class:`owslib.wps.WebProcessingService`\n",
       "    verbose (str): passed to :class:`owslib.wps.WebProcessingService`\n",
       "    progress (bool): If True, enable interactive user mode.\n",
       "    version (str): WPS version to use.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check wps info\n",
    "thunderbird?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Climos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process runs [generate_climos](https://github.com/pacificclimate/climate-explorer-data-prep/blob/master/README.md#generate_climos-generate-climatological-means), which creates files with climatological means/standard deviations of input data from a netcdf file. The `dry run` outputs metadata information about the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mthunderbird\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_climos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnetcdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconvert_longitudes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplit_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplit_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclimo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresolutions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Generate files containing climatological means from input files of daily, monthly, or yearly data that adhere to the PCIC metadata standard (and consequently to CMIP5 and CF standards).\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "netcdf : ComplexData:mimetype:`application/x-netcdf`, :mimetype:`application/x-ogc-dods`\n",
       "    NetCDF file\n",
       "operation : {'mean', 'std'}string\n",
       "    Operation to perform on the datasets\n",
       "climo : {'6190', '7100', '8110', '2020', '2050', '2080'}string\n",
       "    Year ranges\n",
       "resolutions : {'all', 'yearly', 'seasonal', 'monthly'}string\n",
       "    Temporal Resolutions\n",
       "convert_longitudes : boolean\n",
       "    Transform longitude range from [0, 360) to [-180, 180)\n",
       "split_vars : boolean\n",
       "    Generate a separate file for each dependent variable in the file\n",
       "split_intervals : boolean\n",
       "    Generate a separate file for each climatological period\n",
       "dry_run : boolean\n",
       "    Checks file to ensure compatible with process\n",
       "\n",
       "Returns\n",
       "-------\n",
       "output : ComplexData:mimetype:`application/metalink+xml; version=4.0`\n",
       "    Metalink object between output files\n",
       "dry_output : ComplexData:mimetype:`text/plain`\n",
       "    File information\n",
       "\u001b[0;31mFile:\u001b[0m      ~/github/pcic/thunderbird/</home/nrados/github/pcic/thunderbird/notebooks/demo_venv/lib/python3.6/site-packages/birdy/client/base.py-0>\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check info on `generate_climos` process\n",
    "thunderbird.generate_climos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry run process\n",
    "netcdf = 'https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/fdd_seasonal_CanESM2_rcp85_r1i1p1_1951-2100.nc'\n",
    "operation = 'mean'\n",
    "climo = '6190'\n",
    "resolutions = 'yearly'\n",
    "dry_run = True\n",
    "\n",
    "dry_output = thunderbird.generate_climos(\n",
    "    netcdf=netcdf, \n",
    "    operation=operation, \n",
    "    climo=climo, \n",
    "    resolutions=resolutions, \n",
    "    dry_run=dry_run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dry Run\n",
      "File: https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/fdd_seasonal_CanESM2_rcp85_r1i1p1_1951-2100.nc\n",
      "climo_periods: {'6190'}\n",
      "project: CMIP5\n",
      "institution: PCIC\n",
      "model: CanESM2\n",
      "emissions: historical, rcp85\n",
      "run: r1i1p1\n",
      "dependent_varnames: ['fdd']\n",
      "time_resolution: seasonal\n",
      "is_multi_year_mean: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process dry run output\n",
    "req = requests.get(dry_output.get()[0])\n",
    "print(req.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate climos\n",
    "output = thunderbird.generate_climos(\n",
    "    netcdf=netcdf, \n",
    "    operation=operation, \n",
    "    climo=climo, \n",
    "    resolutions=resolutions, \n",
    "    dry_run=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<metaurl mediatype=\"application/x-netcdf\">\n",
       "     http://localhost:5001/outputs/f91e589e-b7cf-11ea-a36c-dc71961151bb/fdd_aClimMean_BCCAQ_CanESM2_historical+rcp85_r1i1p1_19610101-19901231_Canada.nc\n",
       "    </metaurl>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process normal output\n",
    "req = requests.get(output.get()[0])\n",
    "BeautifulSoup(BeautifulSoup(req.content.decode('utf-8')).prettify()).metaurl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Merged Climos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process runs [split_merged_climos](https://github.com/pacificclimate/climate-explorer-data-prep/blob/master/README.md#split_merged_climos-split-climo-means-files-into-per-interval-files-month-season-year), which splits climatological means files into one file per time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mthunderbird\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_merged_climos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetcdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloglevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'INFO'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Split climo means files into one file per time interval\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "netcdf : ComplexData:mimetype:`application/x-netcdf`, :mimetype:`application/x-ogc-dods`\n",
       "    NetCDF files to process\n",
       "loglevel : {'CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG', 'NOTSET'}string\n",
       "    Logging level\n",
       "\n",
       "Returns\n",
       "-------\n",
       "output : ComplexData:mimetype:`application/metalink+xml; version=4.0`\n",
       "    Metalink object between output files\n",
       "\u001b[0;31mFile:\u001b[0m      ~/github/pcic/thunderbird/</home/nrados/github/pcic/thunderbird/notebooks/demo_venv/lib/python3.6/site-packages/birdy/client/base.py-3>\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check info on `split_merged_climos` process\n",
    "thunderbird.split_merged_climos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test local and opendap files\n",
    "tasmax_climos_local = resource_filename('tests', 'data/tiny_downscaled_tasmax_climos.nc')\n",
    "hydromodel_climos_opendap = \"https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/tiny_hydromodel_gcm_climos.nc\"\n",
    "\n",
    "output = thunderbird.split_merged_climos([tasmax_climos_local, hydromodel_climos_opendap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<metaurl mediatype=\"application/x-netcdf\">\n",
       "      http://localhost:5001/outputs/fc584a2e-b7cf-11ea-a36c-dc71961151bb/tasmax_mClim_BCCAQ2_ACCESS1-0_historical+rcp45_r1i1p1_19610101-19901231.nc\n",
       "     </metaurl>,\n",
       " <metaurl mediatype=\"application/x-netcdf\">\n",
       "      http://localhost:5001/outputs/fc584a2f-b7cf-11ea-a36c-dc71961151bb/tasmax_sClim_BCCAQ2_ACCESS1-0_historical+rcp45_r1i1p1_19610101-19901231.nc\n",
       "     </metaurl>,\n",
       " <metaurl mediatype=\"application/x-netcdf\">\n",
       "      http://localhost:5001/outputs/fc584a30-b7cf-11ea-a36c-dc71961151bb/tasmax_aClim_BCCAQ2_ACCESS1-0_historical+rcp45_r1i1p1_19610101-19901231.nc\n",
       "     </metaurl>,\n",
       " <metaurl mediatype=\"application/x-netcdf\">\n",
       "      http://localhost:5001/outputs/fc584a31-b7cf-11ea-a36c-dc71961151bb/BASEFLOW+EVAP+GLAC_AREA_BAND+GLAC_MBAL_BAND+RUNOFF+SWE_BAND_mClim_VICGL+RGM+HydroCon_ACCESS1-0_historical+rcp45_r1i1p1_19840101-19951231.nc\n",
       "     </metaurl>,\n",
       " <metaurl mediatype=\"application/x-netcdf\">\n",
       "      http://localhost:5001/outputs/fc584a32-b7cf-11ea-a36c-dc71961151bb/BASEFLOW+EVAP+GLAC_AREA_BAND+GLAC_MBAL_BAND+RUNOFF+SWE_BAND_sClim_VICGL+RGM+HydroCon_ACCESS1-0_historical+rcp45_r1i1p1_19840101-19951231.nc\n",
       "     </metaurl>,\n",
       " <metaurl mediatype=\"application/x-netcdf\">\n",
       "      http://localhost:5001/outputs/fc584a33-b7cf-11ea-a36c-dc71961151bb/BASEFLOW+EVAP+GLAC_AREA_BAND+GLAC_MBAL_BAND+RUNOFF+SWE_BAND_aClim_VICGL+RGM+HydroCon_ACCESS1-0_historical+rcp45_r1i1p1_19840101-19951231.nc\n",
       "     </metaurl>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = requests.get(output.get()[0])\n",
    "BeautifulSoup(BeautifulSoup(req.content.decode('utf-8')).prettify()).find_all('metaurl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process runs [update_metadata](https://github.com/pacificclimate/climate-explorer-data-prep/blob/master/README.md#update_metadata-update-metadata-in-a-netcdf-file), which updates metadata from an input file according to instructions provided by a string or `.yaml` file. Rather than a metalink, the output is the updated netcdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mthunderbird\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetcdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Update file containing missing, invalid, or incorrectly named global or variable metadata attributes\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "netcdf : ComplexData:mimetype:`application/x-netcdf`, :mimetype:`application/x-ogc-dods`\n",
       "    NetCDF file\n",
       "updates : string\n",
       "    The filepath of an updates file that specifies what to do to the metadata it finds in the NetCDF file\n",
       "\n",
       "Returns\n",
       "-------\n",
       "output : ComplexData:mimetype:`application/x-netcdf`\n",
       "    Output Netcdf Files\n",
       "\u001b[0;31mFile:\u001b[0m      ~/github/pcic/thunderbird/</home/nrados/github/pcic/thunderbird/notebooks/demo_venv/lib/python3.6/site-packages/birdy/client/base.py-2>\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check info on `update_metadata` process\n",
    "thunderbird.update_metadata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = resource_filename(\"tests\", \"metadata-conversion/simple-conversion.yaml\")\n",
    "netcdf = \"https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/gdd_annual_CanESM2_rcp85_r1i1p1_1951-2100.nc\"\n",
    "output = thunderbird.update_metadata(updates = updates, netcdf = netcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_metadataResponse(\n",
      "    output='http://localhost:5001/outputs/ffe82fa6-b7cf-11ea-a36c-dc71961151bb/gdd_annual_CanESM2_rcp85_r1i1p1_1951-2100_copy.nc'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(output.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Prsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process runs [generate_prsn](https://github.com/pacificclimate/climate-explorer-data-prep/blob/master/README.md#generate_prsn-generate-snowfall-file), which generates a `snowfall_flux` file from precipitation, tasmin, and tasmax input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mthunderbird\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_prsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtasmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtasmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloglevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'INFO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Generate precipitation as snow file from precipitation and minimum/maximum temperature data\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "prec : ComplexData:mimetype:`application/x-netcdf`, :mimetype:`application/x-ogc-dods`\n",
       "    Precipitation file to process\n",
       "tasmin : ComplexData:mimetype:`application/x-netcdf`, :mimetype:`application/x-ogc-dods`\n",
       "    Tasmin file to process\n",
       "tasmax : ComplexData:mimetype:`application/x-netcdf`, :mimetype:`application/x-ogc-dods`\n",
       "    Tasmax file to process\n",
       "chunk_size : integer\n",
       "    Number of time slices to be read/written at a time\n",
       "output_file : string\n",
       "    Optional custom name of output file\n",
       "loglevel : {'CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG', 'NOTSET'}string\n",
       "    Logging level\n",
       "dry_run : boolean\n",
       "    Checks file to ensure compatible with process\n",
       "\n",
       "Returns\n",
       "-------\n",
       "output : ComplexData:mimetype:`application/metalink+xml; version=4.0`\n",
       "    Metalink object between output files\n",
       "dry_output : ComplexData:mimetype:`text/plain`\n",
       "    File information\n",
       "\u001b[0;31mFile:\u001b[0m      ~/github/pcic/thunderbird/</home/nrados/github/pcic/thunderbird/notebooks/demo_venv/lib/python3.6/site-packages/birdy/client/base.py-1>\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check info on `generate_prsn` process\n",
    "thunderbird.generate_prsn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test local and opendap files\n",
    "pr_file_local = resource_filename(\"tests\", \"data/pr_week_test.nc\")\n",
    "tasmin_file_opendap = \"https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/tasmin_day_BCCAQv2%2BANUSPLIN300_NorESM1-M_historical%2Brcp26_r1i1p1_19500101-19500107.nc\"\n",
    "tasmax_file_opendap = \"https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/tasmax_day_BCCAQv2%2BANUSPLIN300_NorESM1-M_historical%2Brcp26_r1i1p1_19500101-19500107.nc\"\n",
    "\n",
    "dry_output = thunderbird.generate_prsn(pr_file_local, tasmin_file_opendap, tasmax_file_opendap, chunk_size=50, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dry Run\n",
      "File: /tmp/pywps_process_5_3uas1l/pr_week_test.nc\n",
      "project: CMIP5\n",
      "model: NorESM1-M\n",
      "institute: PCIC\n",
      "experiment: historical,rcp26\n",
      "ensemble_member: r1i1p1\n",
      "dependent_varnames: ['pr']\n",
      "File: https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/tasmin_day_BCCAQv2%2BANUSPLIN300_NorESM1-M_historical%2Brcp26_r1i1p1_19500101-19500107.nc\n",
      "project: CMIP5\n",
      "model: NorESM1-M\n",
      "institute: PCIC\n",
      "experiment: historical,rcp26\n",
      "ensemble_member: r1i1p1\n",
      "dependent_varnames: ['tasmin']\n",
      "File: https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/tasmax_day_BCCAQv2%2BANUSPLIN300_NorESM1-M_historical%2Brcp26_r1i1p1_19500101-19500107.nc\n",
      "project: CMIP5\n",
      "model: NorESM1-M\n",
      "institute: PCIC\n",
      "experiment: historical,rcp26\n",
      "ensemble_member: r1i1p1\n",
      "dependent_varnames: ['tasmax']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(dry_output.get()[0])\n",
    "print(req.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = thunderbird.generate_prsn(pr_file_local, tasmin_file_opendap, tasmax_file_opendap, chunk_size=50, dry_run=False, output_file=\"prsn_test_mixed.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<metaurl mediatype=\"application/x-netcdf\">\n",
       "     http://localhost:5001/outputs/bf4d1410-b712-11ea-afd0-c86000e3f2fd/prsn_test_mixed.nc\n",
       "    </metaurl>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = requests.get(output.get()[0])\n",
    "BeautifulSoup(BeautifulSoup(req.content.decode('utf-8')).prettify()).metaurl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Flow Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process runs [decompose_flow_vectors](https://github.com/pacificclimate/climate-explorer-data-prep#decompose_flow_vectors-create-normalized-unit-vector-fields-from-a-vic-routing-file), which writes to outfile a netCDF containing normalized vector arrays generated from variable in infile. It does not change infile or copy any other variables or axes to outfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check info on `generate_prsn` process\n",
    "thunderbird.decompose_flow_vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_vectors_file = \"https://docker-dev03.pcic.uvic.ca/twitcher/ows/proxy/thredds/dodsC/datasets/TestData/sample_flow_parameters.nc\"\n",
    "variable = \"Flow_Direction\"\n",
    "dest_file = \"output.nc\"\n",
    "output = thunderbird.decompose_flow_vectors(netcdf=flow_vectors_file, variable=variable, dest_file=dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
